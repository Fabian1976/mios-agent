#!/usr/bin/python
#
# Explenation fields /proc/diskstats
#  The first 3 fields are to identify the device (we'll start counting at 0 as almost all programming languages do)
#  Field  0 -- The MAJOR number
#  Field  1 -- The MINOR number
#  Field  2 -- The devicename
#
# For IO measurements we'll use the remaining field
#  Field  3 -- # of reads completed
#      This is the total number of reads completed successfully.
#  Field  4 -- # of reads merged
#      Reads and writes which are adjacent to each other may be merged for
#      efficiency.  Thus two 4K reads may become one 8K read before it is
#      ultimately handed to the disk, and so it will be counted (and queued)
#      as only one I/O.  This field lets you know how often this was done.
#  Field  5 -- # of sectors read
#      This is the total number of sectors read successfully (default sectorsize = 512 bytes).
#  Field  6 -- # of milliseconds spent reading
#      This is the total number of milliseconds spent by all reads (as
#      measured from __make_request() to end_that_request_last()).
#  Field  7 -- # of writes completed
#      This is the total number of writes completed successfully.
#  Field  8 -- # of writes merged
#      Reads and writes which are adjacent to each other may be merged for
#      efficiency.  Thus two 4K reads may become one 8K read before it is
#      ultimately handed to the disk, and so it will be counted (and queued)
#      as only one I/O.  This field lets you know how often this was done.
#  Field  9 -- # of sectors written
#      This is the total number of sectors written successfully (default sectorsize = 512 bytes).
#  Field 10 -- # of milliseconds spent writing
#      This is the total number of milliseconds spent by all writes (as
#      measured from __make_request() to end_that_request_last()).
#  Field 11 -- # of I/Os currently in progress
#      The only field that should go to zero. Incremented as requests are
#      given to appropriate struct request_queue and decremented as they finish.
#  Field 12 -- # of milliseconds spent doing I/Os
#      This field is increases so long as field 11 is nonzero.
#  Field 13 -- weighted # of milliseconds spent doing I/Os
#      This field is incremented at each I/O start, I/O completion, I/O
#      merge, or read of these stats by the number of I/Os in progress
#      (field 9) times the number of milliseconds spent doing I/O since the
#      last update of this field.  This can provide an easy measure of both
#      I/O completion time and the backlog that may be accumulating.

__author__    = "Jan van de Beek, Fabian van der Hoeven"
__copyright__ = "Copyright (C) 2013 Vermont 24x7"
__version__   = "4.0"

import sys, os, time, getopt
# Add mios-agent LIB to path
try:
	magent_home = os.environ['MAGENT_HOME']
except: #Send message to stdout as logger is not initialized yet
	print "Environment variabele MAGENT_HOME not set. Assuming default of: /opt/mios/mios-agent"
	magent_home = "/opt/mios/mios-agent"
sys.path.append(magent_home + '/lib')

from threading import *
from socket import *
from struct import *
import struct
import re
import ConfigParser
import platform
import getopt
import logging, logging.config
import cloghandler
try:
        import json
except ImportError:
        import simplejson as json
import threading
try:
	from daemon import Daemon
except:
	print "\nCannot import daemon.pyc from lib path ($MAGENT_HOME/lib)\nIs MIOS-AGENT properly installed?"
	raise
#import ast #ast.literal_eval
#literal_eval
from compiler import parse
from compiler.ast import *

def literal_eval(node_or_string):
     """
     Safely evaluate an expression node or a string containing a Python
     expression.  The string or node provided may only consist of the  
following
     Python literal structures: strings, numbers, tuples, lists, dicts,  
booleans,
     and None.
     """
     _safe_names = {'None': None, 'True': True, 'False': False}
     if isinstance(node_or_string, basestring):
         node_or_string = parse(node_or_string, mode='eval')
     if isinstance(node_or_string, Expression):
         node_or_string = node_or_string.node
     def _convert(node):
         if isinstance(node, Const) and isinstance(node.value,
                 (basestring, int, float, long, complex)):
              return node.value
         elif isinstance(node, Tuple):
             return tuple(map(_convert, node.nodes))
         elif isinstance(node, List):
             return list(map(_convert, node.nodes))
         elif isinstance(node, Dict):
             return dict((_convert(k), _convert(v)) for k, v
                         in node.items)
         elif isinstance(node, Name):
             if node.name in _safe_names:
                 return _safe_names[node.name]
         elif isinstance(node, UnarySub):
             return -_convert(node.expr)
         raise ValueError('malformed string')
     return _convert(node_or_string)

oracle = None
probes = None
config = None
disk_stat = None
postgres = None
apache_stat = None
mongodb = None

class Config:

	def __init__(self, conf_file):

		self.config          = None
		self.listen_ip       = ''
		self.listen_port     = 0
		self.hostname        = ''
		self.domain          = ''
		self.fqdn            = getfqdn()
		self.zabbix_agent    = ''
		self.zabbix_port     = 0
		self.oracle_sids     = {}
		self.oracle_oa_dir   = ''
		self.postgres_dbs    = {}
		self.mongo_db        = {}
		self.magent_home     = magent_home

		self.conf_file = conf_file
		if not os.path.exists(self.conf_file):
			print "Can't open config file %s" % self.conf_file
			exit(1)

		self.config = ConfigParser.ConfigParser()
		self.config.read(self.conf_file)

	def parse(self):

		try:
			self.listen_ip      = self.config.get('common', 'listen_ip')
		except:
			self.listen_ip      = 'localhost'

		try:
			self.listen_port    = int(self.config.get('common', 'listen_port'))
		except:
			self.listen_port    = 10050

		try:
			self.hostname       = self.config.get('common', 'hostname')
		except:
			self.hostname       = platform.node()

		try:
			self.domain         = self.config.get('common', 'domain')
		except:
			self.domain         = '.'.join(getfqdn().split('.')[1:])

		try:
			self.zabbix_agent   = self.config.get('common', 'zabbix_agent')
		except:
			self.zabbix_agent   = 'localhost'

		try:
			self.zabbix_port    = self.config.getint('common', 'zabbix_port')
		except:
			self.zabbix_port    = 10051

		print "[common]"
		print "INI file             : %s" % self.conf_file
		print "Listen on ip address : %s" % self.listen_ip
		print "Listen on port       : %d" % self.listen_port
		print "Hostname             : %s" % self.hostname
		print "Zabbix agent ip      : %s" % self.zabbix_agent
		print "Zabbix agent port    : %s" % self.zabbix_port

		sections = self.config.sections()
		for section in sections:
			if section == 'common':
				continue
			dbtype = section.split('.')[0]
			if dbtype == 'oracle':
				try:
					sid                     = section.split('.')[1]
				except:
					print "No SID specified. Please review example section in config file"
					exit(1)
				if sid == '':
					print "No SID specified. Please review example section in config file"
					exit(1)
				user                    = self.config.get(section, 'user')
				password                = self.config.get(section, 'password')
				host			= self.config.get(section, 'host')
				port			= self.config.get(section, 'port')
				service			= self.config.get(section, 'service')
				self.oracle_sids[sid]   = (user, password, host, port, service)
				self.oracle_oa_dir      = self.config.get(section, 'oa_dir')
				global OA_DIR
				OA_DIR                  = self.oracle_oa_dir
				print ""
				print section
				print "Oracle SID		: %s" % sid
				print "Oracle user		: %s" % user
				print "Oracle password		: %s" % password
				print "Oracle OA_DIR		: %s" % self.oracle_oa_dir
			if dbtype == 'postgres':
				try:
					dbname			= section.split('.')[1]
				except:
					print "No DBNAME specified. Please review example section in config file"
					exit(1)
				try:
					host			= self.config.get(section, 'host')
				except:
					print "No host specified for db: %s. Please review example section in config file" % dbname
					exit(1)
				try:
					port			= self.config.get(section, 'port')
				except:
					print "No port specified for db: %s. Please review example section in config file" % dbname
					exit(1)
				try:
					user			= self.config.get(section, 'user')
				except:
					print "No user specified for db: %s. Please review example section in config file" % dbname
					exit(1)
				try:
					password		= self.config.get(section, 'password')
				except:
					print "No password specified for db: %s. Please review example section in config file" % dbname
					exit(1)
				self.postgres_dbs[dbname] = (host, port, user, password)
				print ""
				print section
				print "Postgres DB		: %s" % dbname
				print "Postgres host		: %s" % host
				print "Postgres port		: %s" % port
				print "Postgres user		: %s" % user
				print "Postgres password	: %s" % password
			if dbtype == 'mongo':
				try:
					host			= self.config.get(section, 'host')
				except:
					print "No host specified for mongodb. Please review example section in config file. Assuming default of localhost"
					host			= 'localhost'
				try:
					port			= self.config.get(section, 'port')
				except:
					print "No port specified for mongodb. Please review example section in config file. Assuming default of 27017"
					port			= 27017
				try:
					user			= self.config.get(section, 'user')
				except:
					print "No user specified for mongodb. Please review example section in config file. Assuming no user is needed"
					user			= ''
					password		= ''
				if user <> '':
					try:
						password	= self.config.get(section, 'password')
					except:
						print "No password specified for mongodb (user: %s). Please review example section in config file"
						exit(1)
				try:
					binary			= self.config.get(section, 'bin')
				except:
					print "No binary specified for mongodb. Please review example section in config file. Trying to find executable in default location"
					binary			= '/usr/bin/mongo'
					if not os.path.exists(binary):
						print "Binary not found in default location (/usr/bin). Please add it to the config"
						exit(1)
				if user <> '':
#					replicaSet_status = '%s --host %s --port %s --username %s --password %s --quiet --eval "printjson(rs.status())"' % (binary, host, port, user, password)
					connection_string = '%s --host %s --port %s --username %s --password %s --quiet --eval ' % (binary, host, port, user, password)
				else:
					connection_string = '%s --host %s --port %s --quiet --eval ' % (binary, host, port)
				self.mongo_db[section] = (connection_string)
				print ""
				print section
				print "MongoDB host		: %s" % host
				print "MongoDB port		: %s" % port
				print "MongoDB user		: %s" % user
				print "MongoDB password		: %s" % password
				print "MongoDB binary		: %s" % binary
			if dbtype not in ('oracle', 'postgres', 'mongo'):
				print "Unsupported database type: %s" % dbtype

	def reparse(self):
		rootLogger.info("Rereading config file...")
		if not os.path.exists(self.conf_file):
			rootLogger.error("Can't open config file %s. Unable to reload configuration. Assuming current configuration." % self.conf_file)
		else:
			new_conf     = None
			oracle_sids  = {}
			postgres_dbs = {}

			new_conf = ConfigParser.ConfigParser()
			new_conf.read(self.conf_file)
			sections = new_conf.sections()
			aantal_sids = 0 # Oracle
			aantal_dbs  = 0 # Postgres
			for section in sections:
				if section == 'common':
					continue
				dbtype = section.split('.')[0]
				if dbtype == 'oracle':
					aantal_sids += 1
					try:
						sid = section.split('.')[1]
						user     = new_conf.get(section, 'user')
						password = new_conf.get(section, 'password')
						host     = new_conf.get(section, 'host')
						port     = new_conf.get(section, 'port')
						service  = new_conf.get(section, 'service')
						oracle_sids[sid] = (user,password, host, port, service)
					except:
						rootLogger.error("SID (%s) not correctly specified in config file. Please review example section in config file" % section)
					if sid == '':
						rootLogger.error("SID (%s) not correctly specified in config file. Please review example section in config file" % section)
				if dbtype == 'postgres':
					aantal_dbs += 1
					try:
						db = section.split('.')[1]
						host = new_conf.get(section, 'host')
						port = new_conf.get(section, 'port')
						user = new_conf.get(section, 'user')
						password = new_conf.get(section, 'password')
						postgres_dbs[db] = (host, port, user, password)
					except:
						rootLogger.error("DB (%s) not correctly specified in config file. Please review example section in config file" % section)
					if db == '':
						rootLogger.error("DB (%s) not correctly specified in config file. Please review example section in config file" % section)
			for sid in oracle_sids:
				if sid not in self.oracle_sids:
					# We have a new connection
					self.oracle_sids[sid] = oracle_sids[sid]
					rootLogger.debug("Found new SID in config: %s. Trying to connect" % sid)
					oracle.add_connection()
			for sid in self.oracle_sids:
				if sid not in oracle_sids:
					# We have a removed connection
					rootLogger.debug("A SID has been removed from the config: %s. Removing connection" % sid)
					oracle.remove_connection(sid)
			rootLogger.debug("Aantal sids in conf: %s. SIDS: %s" % (aantal_sids, oracle_sids))
			rootLogger.debug("Aantal sids in mem: %s. SIDS: %s" % (len(self.oracle_sids), self.oracle_sids))

			for db in postgres_dbs:
				if db not in self.postgres_dbs:
					# We have a new connection
					self.postgres_dbs[db] = postgres_dbs[db]
					rootLogger.debug("Found new DB in config: %s. Trying to connect" % db)
					postgres.add_connection()
			for db in self.postgres_dbs:
				if db not in postgres_dbs:
					# We have a removed connection
					rootLogger.debug("A DB has been removed from the config: %s. Removing connection" % db)
					postgres.remove_connection(db)
			rootLogger.debug("Aantal dbs in conf: %s. DBS: %s" % (aantal_dbs, postgres_dbs))
			rootLogger.debug("Aantal dbs in mem: %s. DBS: %s" % (len(self.postgres_dbs), self.postgres_dbs))

class Probes:

	def __init__(self):

		self.probe_list = {}

		rootLogger.info("Caching probes...")
		for file in os.listdir(config.magent_home + '/probes'):
			if file != 'sync_probes':
				f = open(config.magent_home + '/probes/' + file)
				type = f.readline()
				try:
					type = type.split('=')[1].strip()
				except:
					rootLogger.error("Found probes with no type definition on the first line: %s" % file)
					type = 'unknown'
				action = f.read()
				rootLogger.debug("Probe cached - type: %s, action: %s" % (type, action))
				self.probe_list[file] = [type, action]
				f.close()

	def get_action(self, probe):

		try:
			return self.probe_list[probe][1]
		except KeyError:
			rootLogger.info("Probe not found in cache. Trying to load new probe: %s" % probe)
			if os.path.exists(config.magent_home + '/probes/' + probe):
				f = open(config.magent_home + '/probes/' + probe)
				type = f.readline()
				try:
					type = type.split('=')[1].strip()
				except:
					rootLogger.error("Found probes with no type definition on the first line: %s" % probe)
					type = 'unknown'
				action = f.read()
				self.probe_list[probe] = [type, action]
				f.close()
				return self.probe_list[probe][1]
			else:
				rootLogger.error("No probe file: %s" % probe)
				return -1

	def refreshProbes(self):

		rootLogger.info("Refreshing probes cache...")
		for file in os.listdir(config.magent_home + '/probes'):
			if file != 'sync_probes':
				f = open(config.magent_home + '/probes/' + file)
				type = f.readline()
				try:
					type = type.split('=')[1].strip()
				except:
					rootLogger.error("Found probes with no type definition on the first line: %s" % file)
					type = 'unknown'
				action = f.read()
				rootLogger.debug("Probe cached - type: %s, action: %s" % (type, action))
				self.probe_list[file] = [type, action]
				f.close()

class Oracle(object):

	def __init__(self, instances):

		self.oracle_support  = 0
		self.connections     = []
		self.cursor          = []
		self.version         = []
		self.user            = []
		self.password        = []
		self.host	     = []
		self.port	     = []
		self.service	     = []
		self.sids            = []
		self.instances       = instances
		self.logger          = logging.getLogger(type(self).__name__)

		try:
			import cx_Oracle
			self.cx_Oracle = cx_Oracle
			self.oracle_support = 1
			self.logger.info("Sucessfully loaded cx_Oracle module")
		except ImportError:
			self.logger.critical("Module cx_Oracle is not installed, please install it!")
			raise
		except:
			self.logger.critical("Error while loading Module cx_Oracle!")
			raise

		if self.oracle_support == 0:
			return None

		for instance in instances:
			user, password, host, port, service = instances[instance]

			sql_file = OA_DIR + "/" + instance + "/sql/mios.sql"
			if os.path.exists(sql_file):
				sql = open(sql_file, "r")
				line = sql.read()
				m = re.search('^\s*connect\s+(\w+)\/(\S+)\s', line)
				if m:
					self.user.append(m.group(1))
					self.password.append(m.group(2))
				else:
					self.logger.error("instance %s has no file %s" % (instance, sql_file))
				sql.close()
			elif user == '' or password == '':
				self.logger.error("File: %s doesn't exist and user / password not specified in config file." % sql_file)
				exit(1)

			self.user.append(user)
			self.password.append(password)
			self.host.append(host)
			self.port.append(port)
			self.service.append(service)
			self.sids.append(instance)
			self.connections.append(None)
			self.cursor.append(None)
			self.version.append('')
			indx = self.sids.index(instance)
			self.connect(indx)

	def connect(self, indx):

		while self.connections[indx] == None:
			try:
				self.connections[indx]  = self.cx_Oracle.connect(user="%s" % self.user[indx], password="%s" % self.password[indx], dsn="%s:%s/%s" % (self.host[indx], self.port[indx], self.service[indx]))
				self.logger.info("Connection succesful (%s)" % self.sids[indx])
				time.sleep(1)
				self.cursor[indx]       = self.connections[indx].cursor()
				self.version[indx]      = self.connections[indx].version
				self.logger.info("Connected to Oracle version %s SID: %s" % (self.version[indx], self.sids[indx]))
			except Exception, e:
				self.logger.critical("Unable to connect to Oracle (%s)" % self.sids[indx])
				self.logger.critical("ORA: Additional information: %s" % e)
				self.logger.info("Trying to reconnect in 10 seconds")
				time.sleep(10)

	def add_connection(self):

		for instance in self.instances:
			if instance not in self.sids:
				user, password, host, port, service = self.instances[instance]
				self.user.append(user)
				self.password.append(password)
				self.host.append(host)
				self.port.append(port)
				self.service.append(service)
				self.sids.append(instance)
				self.connections.append(None)
				self.cursor.append(None)
				self.version.append('')
				indx = self.sids.index(instance)
				self.connect(indx)

	def disconnect(self, indx):

		self.cursor[indx].close()
		self.connections[indx].close()

	def remove_connection(self, sid):
		indx = self.sids.index(sid)
		self.logger.debug("SID that needs to be removed: %s" % sid)
		self.logger.debug("INDX of SID: %s" % indx)
		# Properly close cursor and connection to database
		self.disconnect(indx)
		# Properly destroy objects associated to this connection
		del self.cursor[indx]
		del self.connections[indx]
		del self.user[indx]
		del self.password[indx]
		del self.host[indx]
		del self.port[indx]
		del self.service[indx]
		del self.sids[indx]
		del self.version[indx]
		del config.oracle_sids[sid]

	def reconnect(self, data):

		if  data.find('[') > 0:
			(item, arguments) = data.split('[')
			arguments = arguments.replace(']','')
		else:
			self.logger.error("no oracle sid specified")
			return None
		arguments = arguments.replace(' ','')
		arguments = arguments.rstrip()
		sid = ''
		if  data.find(',') > 0:
			fields = arguments.split(',')
			sid = fields[0]
		else:
			sid = arguments

		if not sid in self.sids:
			self.logger.error("Unknown SID: %s" % sid)
			self.logger.error("Additional info: %s" % data)
			return

		indx = self.sids.index(sid)
		self.logger.debug("indx: %s" % indx)

		try:
			self.connections[indx]  = self.cx_Oracle.connect(user="%s" % self.user[indx], password="%s" % self.password[indx], dsn="%s:%s/%s" % (self.host[indx], self.port[indx], self.service[indx]))
		except Exception, e:
			self.logger.critical("Unable to connect to Oracle")
			self.logger.critical("ORA: Additional information: %s" % e)
		self.cursor[indx]      = self.connections[indx].cursor()
		self.version[indx]    = self.connections[indx].version
		self.logger.info("Connect to Oracle version %s SID: %s" % (self.version[indx], self.sids[indx]))

	def get(self, data):

		fields=[]

		if self.oracle_support == 0:
			self.logger.error("Oracle not supported")
			return None

		if  data.find('[') > 0:
			(item, arguments) = data.split('[')
			arguments = arguments.replace(']','')
		else:
			self.logger.error("no oracle sid specified")
			return None
		arguments = arguments.replace(' ','')
		arguments = arguments.rstrip()
		sid = ''
		if  data.find(',') > 0:
			fields = arguments.split(',')
			sid = fields[0]
		else:
			sid = arguments
		top_item = item.split('.')
		action=probes.get_action(item)
		m = re.search('MIOS_ARG_2', action)
		if m:
			action = re.sub('MIOS_ARG_2', fields[1], action)

		if not sid in self.sids:
			self.logger.error("SID not found in list of SIDS from config file")
			return -1

		try:
			indx = self.sids.index(sid)
			try:
				self.cursor[indx].execute(action)
			except Exception, e:
				self.logger.error("ORA: Failed to execute query: %s" % action)
				self.logger.error("ORA: Additional info: %s" % e)
				ORA_error = e.split(':')[0]
				if ORA_error == 'ORA-03113': #Not connected to Oracle
					return -2 #Forces parent to reconnect
				else:
					return -1

			try:
				value = self.cursor[indx].fetchone()[0]
			except Exception, e:
				self.logger.error("ORA: Failed to fetch result from resultset")
				self.logger.error("ORA: Additional info: %s" % e)
				return -1

			self.logger.debug("indx: %d sid: %s action: %s value: %s" % (indx, sid, action.rstrip("\n\r"), str(value)))
			return value
		except:
			self.logger.error("Error in Oracle connection SID: %s" % sid)
			return -2

	def execute(self, sid, query):

		if self.oracle_support == 0:
			self.logger.error("Oracle not supported")
			return None

		if not sid in self.sids:
			return -1
		try:
			indx = self.sids.index(sid)
			try:
				self.cursor[indx].execute(query)
			except Exception, e:
				self.logger.error("ORA: Failed to execute query: %s" % action)
				self.logger.error("ORA: Additional info: %s" % e)
				return -1

			try:
				value = self.cursor[indx].fetchall()
			except Exception, e:
				self.logger.error("ORA: Failed to fetch resultset")
				self.logger.error("ORA: Additional info: %s" % e)
				return -1

			self.logger.debug("indx: %d sid: %s action: %s value: %s" % (indx, sid, query, str(value)))
			return value
		except:
			self.logger.error("Error in Oracle connection SID: %s" % sid)
			return -2

class Postgres(object):

	def __init__(self, instances):

		self.postgres_support = 0
		self.connections      = []
		self.cursor           = []
		self.version          = []
		self.host             = []
		self.port             = []
		self.user             = []
		self.password         = []
		self.dbs              = []
		self.instances        = instances
		self.logger           = logging.getLogger(type(self).__name__)

		try:
			import psycopg2
			self.psycopg2 = psycopg2
			self.postgres_support = 1
			self.logger.info("Successfully loaded psycopg2 module")
		except ImportError:
			self.logger.error("Module psycopg2 is not installed, please install it!")
			raise
		except:
			self.logger.error("Error while loading psycopg2 module!")
			raise

		if self.postgres_support == 0:
			return None

		for instance in instances:
			host, port, user, password = instances[instance]
			self.host.append(host)
			self.port.append(port)
			self.user.append(user)
			self.password.append(password)
			self.dbs.append(instance)
			self.connections.append(None)
			self.cursor.append(None)
			self.version.append('')
			indx = self.dbs.index(instance)
			self.connect(indx)

	def connect(self, indx):

		while self.connections[indx] == None:
			try:
				self.connections[indx] = self.psycopg2.connect("host='%s' port='%s' dbname='%s' user='%s' password='%s'" % (self.host[indx], self.port[indx], self.dbs[indx], self.user[indx], self.password[indx]))
				self.logger.info("Connection succesful (%s)" % self.dbs[indx])
				time.sleep(1)
			except Exception, e:
				self.logger.critical("Unable to connect to Postgres")
				self.logger.critical("PG: Additional information: %s" % e)
				self.logger.info("Trying to reconnect in 10 seconds")
				time.sleep(10)
		self.cursor[indx]      = self.connections[indx].cursor()
		self.cursor[indx].execute('select version()')
		self.version[indx]     = self.cursor[indx].fetchone()
		self.logger.info("Connect to Postgres version %s DB: %s" % (self.version[indx], self.dbs[indx]))

	def add_connection(self):

		for instance in self.instances:
			if instance not in self.dbs:
				host, port, user, password = self.instances[instance]
				self.host.append(host)
				self.port.append(port)
				self.user.append(user)
				self.password.append(password)
				self.dbs.append(instance)
				self.connections.append(None)
				self.cursor.append(None)
				self.version.append('')
				indx = self.dbs.index(instance)
				self.connect(indx)

	def disconnect(self, indx):

		self.cursor[indx].close()
		self.connections[indx].close()

	def remove_connection(self, db):
		indx = self.dbs.index(db)
		self.logger.debug("DB that needs to be removed: %s" % db)
		self.logger.debug("INDX of DB: %s" % indx)
		# Properly close cursor and connection to database
		self.disconnect(indx)
		# Properly destroy objects associated to this connection
		del self.cursor[indx]
		del self.connections[indx]
		del self.host[indx]
		del self.port[indx]
		del self.user[indx]
		del self.password[indx]
		del self.dbs[indx]
		del self.version[indx]
		del config.postgres_dbs[db]

	def reconnect(self, data):

		if data.find('[') > 0:
			(item, arguments) = data.split('[')
			arguments = arguments.replace(']','')
		else:
			self.logger.error("no postgres db specified")
			return None
		arguments = arguments.replace(' ','')
		arguments = arguments.rstrip()
		db = ''
		if data.find(',') > 0:
			fields = arguments.split(',')
			db = fields[0]
		else:
			db = arguments

		if not db in self.dbs:
			return

		indx = self.dbs.index(db)
		print "indx", indx

		self.connections[indx] = self.psycopg2.connect("host='%s' port='%s' dbname='%s' user='%s' password='%s'" % (self.host[indx], self.port[indx], self.dbs[indx], self.user[indx], self.password[indx]))
		self.cursor[indx]      = self.connections[indx].cursor()
		self.cursor[indx].execute('select version()')
		self.version[indx]     = self.cursor[indx].fetchone()
		self.logger.info("Connect to Postgres version %s DB: %s" % (self.version[indx], self.dbs[indx]))

	def get(self, data):

		fields = []

		if self.postgres_support == 0:
			self.logger.error("Postgres not supported")
			return None

		if  data.find('[') > 0:
			(item, arguments) = data.split('[')
			arguments = arguments.replace(']','')
		else:
			self.logger.error("no postgres db specified")
			return None
		arguments = arguments.replace(' ','')
		arguments = arguments.rstrip()
		db = ''
		if  data.find(',') > 0:
			fields = arguments.split(',')
			db = fields[0]
		else:
			db = arguments
		top_item = item.split('.')
		action=probes.get_action(item)
		# Replace MIOS_ARG_1 in probe with 1st argument from Zabbix key
		m = re.search('MIOS_ARG_1', action)
		if m:
			action = re.sub('MIOS_ARG_1', fields[0], action)
		# Replace MIOS_ARG_2 in probe with 1st argument from Zabbix key
		m = re.search('MIOS_ARG_2', action)
		if m:
			action = re.sub('MIOS_ARG_2', fields[1], action)

		if not db in self.dbs:
			self.logger.error("DB not found in list of DBS from config file")
			return -1

		try:
			indx = self.dbs.index(db)
			try:
				self.cursor[indx].execute(action)
			except Exception, e:
				self.logger.error("PG: Failed to execute query: %s" % action)
				self.logger.error("PG: Additional info: %s" % e)
				return -1

			try:
				value = self.cursor[indx].fetchone()[0]
			except Exception, e:
				self.logger.error("PG: Failed to fetch result from resultset")
				self.logger.error("PG: Additional info: %s" % e)
				return -1

			self.logger.debug("indx: %d db: %s action: %s value: %s" % (indx, db, action.rstrip("\n\r"), str(value)))
			# Postgres has to have a commit after each select or else the table (pg_stat_database) will seem static
			# In future maybe filter query's to this table so that not every select has a commit
			self.connections[indx].commit()
			return value
		except:
			self.logger.error("Error in Postgres connection DB: %s" % db)
			return -2
	def execute(self, db, query):
		#TODO
		pass

class NetStats(object):

	# Stats is a dictionary of lists. The dictionary is for the devices and the list of that item is the stats
	# Location items of list:
	#       0 - rx_bytes
	#       1 - rx_packets
	#       2 - rx_errors
	#       3 - rx_dropped
	#       4 - tx_bytes
	#       5 - tx_packets
	#       6 - tx_errors
	#       7 - tx_dropped
	#
	# So {'eth0':[0,1,2,3,4,5,6,7],'eth1':[0,1,2,3,4,5,6,7]} could be a dictionary

	def __init__(self):

		self.net_devices  = []
		self.stats        = {}
		self.last_update  = []
		self.min_interval = 30

		self.init_stats()
		self.update_stats()

	def init_stats(self):

		# Discover ehternet devices
		f = open('/proc/net/dev', 'r')
		# Skip first 2 lines of file (header)
		dummy = f.readline()
		dummy = f.readline()
		for line in f:
				net_dev = line.split(':')[0].strip()
				self.net_devices.append(net_dev)
		f.close()

	def update_stats(self):
		f = open('/proc/net/dev', 'r')
		# Skip first 2 lines of file (header)
		dummy = f.readline()
		dummy = f.readline()
		# We will only read bytes, packets, errors and dropped per interface
		for line in f:
			dev_stats = []
			net_dev = line.split(':')[0].strip()
			fields = line.split(':')[1].split()
			# append rx_bytes
			dev_stats.append(fields[0])
			# append rx_packets
			dev_stats.append(fields[1])
			# append rx_errors
			dev_stats.append(fields[2])
			# append rx_dropped
			dev_stats.append(fields[3])
			# append tx_bytes
			dev_stats.append(fields[8])
			# append tx_packets
			dev_stats.append(fields[9])
			# append tx_errors
			dev_stats.append(fields[10])
			# append tx_dropped
			dev_stats.append(fields[11])
			self.stats[net_dev] = dev_stats
		f.close()
		self.last_update = time.time()

	def get_attr(self, net_dev, stat):

		now = time.time()
		if now - self.last_update > self.min_interval:
			self.update_stats()
		ret = self.stats[net_dev][stat]
		return ret

class Apache(object):

	def __init__(self):

		import urllib
		import csv
		self.urllib       = urllib
		self.csv          = csv
		self.stats        = {}
		self.last_update  = []
		self.min_interval = 30
		self.tempFilename = '/tmp/apache-status'
		self.webserver    = 'localhost'
		self.port         = '80'
		self.url          = '/server-status?auto'
		self.logger       = logging.getLogger(type(self).__name__)

		self.last_update  = 0

	def getMetrics(self):

		try:
			ConnectionString = ("http://%s:%s%s") % (self.webserver, self.port, self.url)
			self.logger.debug("Trying to get metrics using host: %s, port: %s" % (self.webserver, self.port))
			conn = self.urllib.urlopen(ConnectionString)
			URLresponse = conn.read()
			conn.close()
			return URLresponse
		except:
			self.logger.error("Failed to connect to %s" % ConnectionString)
			return -1

	def update_stats(self):

		try:
			ApacheTempFile = open(self.tempFilename, 'w')
		except:
			self.logger.error("Unable to open tempfile %s for writing." % self.tempFilename)
			raise
		ApacheTempFile.write(self.getMetrics())
		Metrics = self.csv.reader(open(self.tempFilename, 'rb'), delimiter = ":", skipinitialspace=True)
		ApacheTempFile.close()
		for Metric in Metrics:
			if Metric[0] == 'Scoreboard':
				self.stats['MaxClients'] = len(Metric[1])
				self.stats['ClosingConnection'] = Metric[1].count('C')
				self.stats['DNSLookup'] = Metric[1].count('D')
				self.stats['GracefullyFinishing'] = Metric[1].count('G')
				self.stats['IdleCleanupOfWorker'] = Metric[1].count('I')
				self.stats['KeepAlive'] = Metric[1].count('K')
				self.stats['Logging'] = Metric[1].count('L')
				self.stats['OpenSlotWithNoCurrentProcess'] = Metric[1].count('.')
				self.stats['ReadingRequest'] = Metric[1].count('R')
				self.stats['SendingReply'] = Metric[1].count('W')
				self.stats['StartingUp'] = Metric[1].count('S')
				self.stats['WaitingForConnection'] = Metric[1].count('_')
			else:
				self.stats[Metric[0]] = Metric[1]
		del Metrics
		del ApacheTempFile
		self.last_update = time.time()

	def getMetric(self, requestedMetric, host, port):
		self.webserver = host
		self.port = port
		now = time.time()
		if now - self.last_update > self.min_interval:
			rootLogger.debug("Apache stats older then min_interval. Update stats.")
			try:
				self.update_stats()
				ret = self.stats[requestedMetric]
			except:
				ret = "ZBX_NOTSUPPORTED"
		else:
			ret = self.stats[requestedMetric]
		return ret

class DiskStats(object):

	def __init__(self):

		self.device_name  = []
		self.major_minor  = []
		self.filesystems  = []
		self.fs_type      = []
		self.read_write   = []
		self.last_update  = 0
		self.stats        = []
		self.MIN_INTERVAL = 30
		self.logger       = logging.getLogger(type(self).__name__)

		self.get_fs_mapping()
		self.init_stats()
		self.update_stats();

	def init_stats(self):

		f = open('/proc/diskstats', 'r')
		for line in f:
			fields = line.split()
			try:
				a="%s-%s" % (fields[0],fields[1])
				i = self.major_minor.index(a)
				fs = self.filesystems[i]
				self.stats[i] = [0,0,0,0,0,0,0,0,0,0,0]
			except:
				pass
		f.close()
		self.last_update = time.time()

	def get_fs_mapping(self):

		f = open('/etc/mtab', 'r')
		for line in f:
			fields = line.split()
			self.device_name.append(fields[0].replace("/dev/",""))
			if fields[2] == "ext4" or fields[2] == "ext3":
				stat  = os.stat(fields[0])
				inode = stat.st_rdev
				self.major_minor.append( "%d-%d" % ( os.major(inode), os.minor(inode)))
				self.logger.debug("Discovered FS: %s (%s-%s)" % ( fields[1], os.major(inode), os.minor(inode) ))
				self.filesystems.append(fields[1])
				self.fs_type.append(fields[2])
				self.read_write.append(fields[3])
				self.stats.append([0,0,0,0,0,0,0,0,0,0,0])
		f.close()

	def update_stats(self):

		f = open('/proc/diskstats', 'r')
		for line in f:
			fields = line.split()
			a="%s-%s" % (fields[0],fields[1])
			try:
				i = self.major_minor.index(a)
				try:
					# Standard fields from /proc/diskstats
					self.stats[i] = [ int(fields[3]), int(fields[4]), int(fields[5]), int(fields[6]), int(fields[7]), int(fields[8]), int(fields[9]), int(fields[10]), int(fields[11]), int(fields[12]), int(fields[13])
					# Calculated custom fields
					, float(fields[12]) / (float(fields[3]) + float(fields[7]))					# Average IO time
					, float(fields[6]) / float(fields[3])								# Average IO read wait time
					, float(fields[10]) / float(fields[7])								# Average IO write wait time
					, (float(fields[6]) + float(fields[10])) / (float(fields[3]) + float(fields[7]))		# Average IO wait time
					, ((float(fields[5]) * 512) / float(fields[3])) / 1024						# Average request size read in Kb
					, ((float(fields[9]) * 512) / float(fields[7])) / 1024						# Average request size write in Kb
					, ((float(fields[5]) + float(fields[9]) * 512) / (float(fields[3]) + float(fields[7]))) / 1024	# Average request size in Kb
					]
				except Exception, e:
#					self.logger.error("ERROR: %s" % e)
					pass
				self.logger.debug("Updated STATS: %s:  READS_COMPLETED: %d,  READS_MERGED: %d,  SECTORS_READ: %d,  IOTIME_READ: %d" % (self.filesystems[i], self.stats[i][0], self.stats[i][1], self.stats[i][2], self.stats[i][3]))
				self.logger.debug("Updated STATS: %s: WRITES_COMPLETED: %d, WRITES_MERGED: %d, SECTORS_WRITE: %d, IOTIME_WRITE: %d" % (self.filesystems[i], self.stats[i][4], self.stats[i][5], self.stats[i][6], self.stats[i][7]))
				self.logger.debug("Updated STATS: %s: CURRENT_IO: %d, IO_TIME: %d, WEIGHT_IO_TIME: %d, AVG_IO_TIME: %.2f" % (self.filesystems[i], self.stats[i][8], self.stats[i][9], self.stats[i][10], self.stats[i][11] ))
				self.logger.debug("Updated STATS: %s: AVG_READ_IOWAIT: %.2f, AVG_WRITE_IOWAIT: %.2f, AVG_IOWAIT: %.2f" % (self.filesystems[i], self.stats[i][12], self.stats[i][13], self.stats[i][14]))
				self.logger.debug("Updated STATS: %s: AVG_REQ_SIZE_READ: %.2f, AVG_REQ_SIZE_WRITE: %.2f, AVG_REQ_SIZE: %.2f" % (self.filesystems[i], self.stats[i][15], self.stats[i][16], self.stats[i][17]))
			except Exception, e:
#				self.logger.error("ERROR: %s" %e)
				pass
		f.close()
		self.last_update = time.time()

	def get_attr(self, fs, nof):

		ret = 0
		now = time.time()
		if now - self.last_update > self.MIN_INTERVAL:
			self.update_stats()
		for line in self.filesystems:
			i = self.filesystems.index(line)
			_fs = self.filesystems[i]
			if _fs == fs:
				ret = self.stats[i][nof]
		self.logger.debug("STATS: %s: %s, returns: %s" % (fs, nof, ret))
		return ret

def flattenDict(d, pre = '', sep = '_'):
	"""Flatten a dict (i.e. dict['a']['b']['c'] => dict['a_b_c'])"""

	new_d = {}
	for k,v in d.items():
		if type(v) == dict:
			new_d.update(flattenDict(d[k], '%s%s%s' % (pre, k, sep)))
		else:
			new_d['%s%s' % (pre, k)] = v
	return new_d

class MongoDB(object):

	def __init__(self):
		self.metrics = {}
		self.last_update  = []
		self.min_interval = 30
		self.last_update  = 0
		self.logger       = logging.getLogger(type(self).__name__)
		self.logger.info("Initializing MongoDB connection")
		self.updateMetrics()

	def updateMetrics(self):

		(connection_string) = config.mongo_db['mongo']
		# get raw metric data
		io = os.popen(connection_string + '"printjson(db.serverStatus())"')
		# clean up
		metrics_str = ''.join(io.readlines()).strip() # convert to string
		metrics_str = re.sub('\w+\((.*)\)', r"\1", metrics_str) # remove functions

		# convert to flattened dict
		try:
			self.metrics.update(flattenDict(json.loads(metrics_str)))
		except ValueError, e:
			self.logger.error("Failed to update Metrics")
			self.logger.error("Additional information: %s" % e)
			self.metrics = {}
		self.logger.debug("MONGO raw metrics: %s" % self.metrics)
		# Get metric db_count. Not part of db.serverStatus()
		io = os.popen(connection_string + '"printjson(db.getMongo().getDBNames())"')
		dbs = ''.join(io.readlines()).strip()
#		db_count = len(ast.literal_eval(dbs))
		db_count = len(literal_eval(dbs))
		self.metrics['db_count'] = db_count
		self.last_update = time.time()

	def getMetric(self, requestedMetric):
		now = time.time()
		if now - self.last_update > self.min_interval:
			self.logger.debug("MongoDB metrics older then min_interval. Updating metrics.")
			try:
				self.updateMetrics()
			except Exception, e:
				self.logger.error("Failed to update metrics")
				self.logger.error("Additional information: %s" % e)
		ret = self.metrics[requestedMetric]
		return ret

class ConnectionHandler:

	def __init__(self, _conn):

		self.conn    = _conn
		self.counter = 1

	def start(self):

		mtype = "ZABBIX"
		data = self.conn.recv(2048)
		data_orig = data
		rootLogger.info("received: %s" % data.rstrip("\n\r"))

		if len(data) >= 4 and data[0:4] == 'MIOS':
			self.process_mios_call(data[4:])
			self.conn.close()
			return

		# Handle probe update
		if len(data) >= 4 and data[0:5] == 'PROBE':
			self.update_probe(data[5:])
			self.conn.close()
			return

		data.replace(' ','')
		item      = ''
		arguments = ''
		if  data.find('[') > 0:
			(item, arguments) = data.split('[')
			arguments = arguments.replace(']','')
		else:
			item = data
			item = item.rstrip()
		arguments = arguments.replace(' ','')
		arguments = arguments.rstrip()
		fields = arguments.split(',')
		top_item = item.split('.')[0]
		rootLogger.debug("Item: %s" % item)

		if top_item == 'oracle':
			if item.split('.')[1] == 'tablespace_discover':
				oracle.logger.debug("DISCOVER TABLESPACES")
				sid = arguments
				rows = oracle.execute(sid, "select tablespace_name from dba_tablespaces where contents = 'PERMANENT'")
				if rows == -1:
					value = "ZBX_NOTSUPPORTED"
				else:
					value = '{ "data":['
					for row in rows:
						oracle.logger.debug('Tablespace found: %s' % row)
						value += '{ "{#TBSNAME}":"%s" },' % row
					value = value[:-1] # Remove last comma. Zabbix 2.2 is stricter with JSON message structure
					value += '] }'
				oracle.logger.debug('value: %s' % value)
			elif item.split('.')[1] == 'tempspace_discover':
				oracle.logger.debug("DISCOVER TEMPSPACES")
				sid = arguments
				rows = oracle.execute(sid, "select tablespace_name from dba_tablespaces where contents = 'TEMPORARY'")
				if rows == -1:
					value = "ZBX_NOTSUPPORTED"
				else:
					value = '{ "data":['
					for row in rows:
						oracle.logger.debug('Tempspace found: %s' % row)
						value += '{ "{#TMPSNAME}":"%s" },' % row
					value = value[:-1] # Remove last comma. Zabbix 2.2 is stricter with JSON message structure
					value += '] }'
				oracle.logger.debug('value: %s' % value)
			elif item.split('.')[1] == 'sid_discover':
				oracle.logger.debug("DISCOVER SID's")
				value = '{ "data":['
				for sid in oracle.sids:
					oracle.logger.debug('SID found: %s' % sid)
					value += '{'
					value += '"{#FQDN}":"%s",' % config.fqdn
					value += '"{#DOMAIN}":"%s",' % config.domain
					value += '"{#SIDNAME}":"%s" },' % sid
				value = value[:-1] # Remove last comma. Zabbix 2.2 is stricter with JSON message structure
				value += '] }'
				oracle.logger.debug('value: %s' % value)
			else:
				value = oracle.get(data)
				if value == -1:
					value = "ZBX_NOTSUPPORTED"
				elif value == -2:
					oracle.logger.error("ORA: Lost connection. Trying to reconnect" % value)
					while value == -2:
						oracle.logger.info("ORA reconnect: sleep 5 seconds...")
						time.sleep(5)
						oracle.reconnect(data)
						value = oracle.get(data)
						if value != -2:
							value = str(value)
				else:
					value = str(value)

			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack("Q%ds" % len(value), len(value), value) )

		elif top_item == 'postgres':
			if item.split('.')[1] == 'dbs_discover':
				postgres.logger.debug("DISCOVER DBS")
				value = '{ "data":['
				for db in postgres.dbs:
					postgres.logger.debug('DB found: %s' % db)
					value += '{'
					value += '"{#FQDN}":"%s",' % config.fqdn
					value += '"{#DOMAIN}":"%s",' % config.domain
					value += '"{#DBNAME}":"%s" },' % db
				value = value[:-1] # Remove last comma. Zabbix 2.2 is stricter with JSON message structure
				value += '] }'
				postgres.logger.debug('DBS discover value: %s' % value)
			else:
				value = postgres.get(data)
				if value == -1:
					value = "ZBX_NOTSUPPORTED"
				elif value == -2:
					postgres.logger.error("PG: Lost connection. Trying to reconnect" % value)
					while value == -2:
						postgres.logger.info("PG reconnect: sleep 5 seconds...")
						time.sleep(5)
						postgres.reconnect(data)
						value = postgres.get(data)
						if value != -2:
							value = str(value)
					pass
				else:
					value = str(value)

			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack("Q%ds" % len(value), len(value), value) )

		elif top_item == 'mongodb':
			if item.split('.')[1] == 'server_status':
				mongodb.logger.debug("MONGO: Getting server_status.%s" % fields[0])
				try:
					value = mongodb.getMetric(fields[0])
					mongodb.logger.debug("MONGO value(%s): %s" % (fields[0], value))
				except e:
					rootLogger.error("MONGO: Failed to get metric")
					rootLogger.error("MONGO: Additional information: %s" % e)
					value = '1'
			value = str(value)
			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack("Q%ds" % len(value), len(value), value) )

		elif item == 'agent.ping':
			sys.stdout.flush()
			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack('QB', 1, 0x30 + 1 ))

		elif top_item == 'perf':
			if item.split('.')[1] == 'io':
				global disk_stat
				if disk_stat is None:
					rootLogger.debug("Received DiskStats request. Creating disk_stat object.")
					disk_stat = DiskStats()
				try:
					if item.split('.')[2] == 'discovery':
						disk_stat.logger.debug("Filesystem discovery")
						value = '{ "data":['
						for fs in disk_stat.filesystems:
							disk_stat.logger.debug("Filesystem discovery found: %s" % fs)
							value += '{ "{#FSNAME}":"%s" },' % fs
						value = value[:-1] # Remove last comma. Zabbix 2.2 is stricter with JSON message structure
						value += '] }'
				except Exception, e:
#					disk_stat.logger.debug("ERROR: %s" %e)
					args = { 'READS_COMPLETED': 0, 'READS_MERGED': 1, 'READS_SECTORS': 2, 'READS_TIME': 3, 'WRITES_COMPLETED': 4, 'WRITES_MERGED': 5, 'WRITES_SECTORS': 6, 'WRITES_TIME': 7, 'IO_QUEUE': 8, 'IO_TIME': 9, 'WIO_TIME': 10, 'AVG_IO_TIME': 11, 'AVG_IO_READ_WAIT': 12, 'AVG_IO_WRITE_WAIT': 13, 'AVG_IO_WAIT': 14, 'AVG_REQ_SIZE_READ': 15, 'AVG_REQ_SIZE_WRITE': 16, 'AVG_REQ_SIZE': 17 }
					value = disk_stat.get_attr(fields[0], args[fields[1].upper()] )
					value = str(value)
					rootLogger.debug("Received io arg1: %s arg2: %s send back: %s length: %s" % (fields[0], fields[1], value, len(value)))
			else:
				# for future custom performance items
				rootLogger.error("Received unsupported performance item: %s" % item.split('.')[1])
				value = "ZBX_NOTSUPPORTED"
			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack("Q%ds" % len(value), len(value), value ) )

		elif item == 'io.wt':
			rootLogger.debug("Received io.wt")
			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack('QB', 1, 0x30 + self.counter )[0:9] )

		elif top_item == 'proc':

			action = 0
			file   = ''
			row    = 0
			col    = 0
			value  = 0

			if item not in ["proc.num", "proc.mem"]: #Ignore Zabbix own proc probes
				action = probes.get_action(item)
			else:
				rootLogger.debug("Ignored: %s, directly sent to zabbix agent" % item)
				action = -1

			if action == -1:
				# Let's give the job to the Zabbix agent
				s = socket(AF_INET, SOCK_STREAM)
				try:
					s.connect((config.zabbix_agent, config.zabbix_port))
					rootLogger.debug("PROC: Connection to Zabbix agent on %s:%s succesfull" % (config.zabbix_agent, config.zabbix_port))
				except:
					rootLogger.error("PROC: Connection to Zabbix agent on %s:%s failed" % (config.zabbix_agent, config.zabbix_port))
				s.send(data_orig)
				header = s.recv(5, MSG_WAITALL)
				bsize = s.recv(8, MSG_WAITALL)
				size = 0
				size = struct.unpack("Q", bsize)[0]
				message = s.recv(size, MSG_WAITALL)
				self.conn.send(header)
				self.conn.send(bsize + message)
				s.close()
				self.conn.close()
				return

			try:
				file, row, col = action.split(' ')
				row = int(row)
				col = int(col)
			except:
				value = -1

			if value == -1:
				value = "ZBX_NOTSUPPORTED"

			else:
				try:
					p = open(file, "r")
					r = 0
					c = 0
					while r <= row:
						line = p.readline()
						if r == row:
							field = line.split()
							value = field[col]
						r += 1

					p.close()
				except Exception, e:
					rootLogger.error("Exception during proc probe: %s" % e)
					value = "ZBX_NOTSUPPORTED"


			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack("Q%ds" % len(value), len(value), value) )

		elif top_item == 'net':
			if item.split('.')[2] == 'discovery':
				rootLogger.debug("Network Interface Discovery")
				value = '{ "data":['
				for net_dev in net_stat.net_devices:
					rootLogger.debug('Net device found: %s' % net_dev)
					value += '{ "{#IFNAME}":"%s" },' % net_dev
				value = value[:-1] # Remove last comma. Zabbix 2.2 is stricter with JSON message structure
				value += '] }'

			elif item.split('.')[2] == 'in':
				if len(fields) == 1:
					rootLogger.debug("NET: Nothing specified. Setting default option for bytes.")
					fields.append('bytes')
				else:
					rootLogger.debug("NET: Received request for %s" % fields[1])
				# rx (in) is numbers 0 through 3
				args = { 'bytes': 0, 'packets': 1, 'errors': 2, 'dropped': 3 }
				try:
					value = net_stat.get_attr(fields[0], args[fields[1]])
				except:
					rootLogger.error("Exception while trying to obtain %s from %s." % (fields[1], fileds[0]))
					value = "ZBX_NOTSUPPORTED"
				rootLogger.debug("Received: %s, %s(%s). Sent back: %s" % (fields[0], fields[1], args[fields[1]], value))

			elif item.split('.')[2] == 'out':
				if len(fields) == 1:
					rootLogger.debug("NET: Nothing specified. Setting default option for bytes.")
					fields.append('bytes')
				else:
					rootLogger.debug("NET: Received request for %s" % fields[1])
				# tx (out) is numbers 4 through 7
				args = { 'bytes': 4, 'packets': 5, 'errors': 6, 'dropped': 7 }
				try:
					value = net_stat.get_attr(fields[0], args[fields[1]])
				except:
					rootLogger.error("Exception while trying to obtain %s from %s." % (fields[1], fileds[0]))
					value = "ZBX_NOTSUPPORTED"
				rootLogger.debug("Received: %s, %s(%s). Sent back: %s" % (fields[0], fields[1], args[fields[1]], value))
			else:
				value = "ZBX_NOTSUPPORTED"

			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack("Q%ds" % len(value), len(value), value) )

		elif top_item == 'apache':
			global apache_stat
			if apache_stat is None:
				rootLogger.debug("Received Apache request. Creating apache object.")
				apache_stat = Apache()
			try:
				metric = item.split('.')[1]
				try:
					host = fields[0]
				except:
					host = apache_stat.webserver
				try:
					port = fields[1]
				except:
					port = apache_stat.port
			except:
				value = "ZBX_NOTSUPPORTED"
			try:
				value = str(apache_stat.getMetric(metric, host, port))
			except Exception, e:
				rootLogger.error("Failed to obtain metric")
				rootLogger.error("APACHE: Additional information: %s" % e)
				value = "ZBX_NOTSUPPORTED"
			self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
			self.conn.send( pack("Q%ds" % len(value), len(value), value) )
		else:

			s = socket(AF_INET, SOCK_STREAM)
			try:
				s.connect((config.zabbix_agent, config.zabbix_port))
				rootLogger.debug("ZBX: Connection to Zabbix agent on %s:%s succesfull" % (config.zabbix_agent, config.zabbix_port))
			except:
				rootLogger.error("ZBX: Connection to Zabbix agent on %s:%s failed" % (config.zabbix_agent, config.zabbix_port))
			s.send(data_orig)
			header = s.recv(5, MSG_WAITALL)
			bsize = s.recv(8, MSG_WAITALL)
			size = 0
			size = struct.unpack("Q", bsize)[0]
			message = s.recv(size, MSG_WAITALL)
			self.conn.send(header)
			self.conn.send(bsize + message)
			s.close()

		self.conn.close()

	def send_data(self, data):
		self.conn.send( pack('4s B', 'ZBXD', 1 )[0:5] )
		self.conn.close()

	def process_mios_call(self, data):

		rootLogger.info("Received MIOS call: %s" % data)
		type, key, value = data.split('\0')
		rootLogger.debug("type: %s key: %s value: %s" % (type, key, str(value)))
		s = socket(AF_INET, SOCK_STREAM)
		try:
			s.connect((config.zabbix_agent, config.zabbix_port))
			rootLogger.debug("MIOS_call: Connection to Zabbix agent on %s:%s succesfull" % (config.zabbix_agent, config.zabbix_port))
			ts = time.time()

			message = "{\n\t\"request\":\"agent data\",\n\t\"data\":[\n\t\t{\n" \
				"\t\t\t\"host\":\"%s\",\n" \
				"\t\t\t\"key\":\"%s\",\n" \
				"\t\t\t\"value\":\"%d\"\n" \
				"\t\t\t\"clock\":%d\n"\
				"}\n" \
				"],\n" \
				"\t\"clock\":%d}" \
				% (config.hostname, key, int(value), ts, ts)

			s.send(pack('4s B', 'ZBXD', 1 )[0:5] )
			msize = len(message)
			template = "Q%ds" % (msize)
			s.send(pack(template, msize, message))
			s.close()
		except:
			rootLogger.error("MIOS_call: Connection to Zabbix agent on %s:%s failed" % (config.zabbix_agent, config.zabbix_port))
			pass

	def update_probe(self, data):

		action      = data[0]
		size_name   = int(data[1:10])
		pointer     = 10 + size_name
		name        = data[10:pointer]
		size_data   = data[pointer:pointer + 9]
		pointer     = pointer + 9
		content     = data[pointer:]

		f = open(config.magent_home + "/probes/%s" % name, "w")
		f.write(content)
		f.close()

class createThread(threading.Thread):
	def __init__(self, target, *args):
		self.target = target
		self.args = args
		threading.Thread.__init__(self)
	def run(self):
		rootLogger.info("Creating thread for function %s" % self.target.__name__)
		self.target(*self.args)

def monitorLogging(interval):
	while True:
		time.sleep(interval)
		if not os.path.exists(config.magent_home + '/conf/logging.conf'):
			rootLogger.error("Can't open logging file %s. Unable to reload logfacility. Assuming current logfacility." % (config.magent_home + '/conf/logging.conf'))
		else:
			rootLogger.info("Reloading logfacility configuration")
			logging.config.fileConfig(config.magent_home + '/conf/logging.conf')

def refreshProbesCache(interval):
	while True:
		time.sleep(interval)
		probes.refreshProbes()

def socketListener():
	s = socket(AF_INET,SOCK_STREAM)
	s.setsockopt(SOL_SOCKET,SO_REUSEADDR,1)
	try:
		s.bind((config.listen_ip, config.listen_port))
		rootLogger.info("Binding to %s:%s" % (config.listen_ip, config.listen_port))
	except Exception, e:
		rootLogger.critical("Unable to bind to specified IP adres. Possibly wrong IP or port allready in use?")
		rootLogger.critical("BIND: Additional information: %s" % e)
		rootLogger.critical("Shutting down")
		daemon.stop()
	s.listen(5)
	while True:
		try:
			con,addr = s.accept()
			ch = ConnectionHandler(con)
			ch.start()
		except:
			pass

def reparseConfig(interval):
	while True:
		time.sleep(interval)
		config.reparse()

def checkMAgentEnvironment():
	try:# Check again so message can also be writed to proper logfile
		magent_home = os.environ['MAGENT_HOME']
	except:
		rootLogger.warning("Environment variabele MAGENT_HOME not set. Assuming default of: /opt/mios/mios-agent")

def checkOracleEnvironment():
	try:
		oracle_base = os.environ['ORACLE_BASE']
	except:
		rootLogger.critical("Environment variabele ORACLE_BASE not set. MIOS-AGENT will not function without it.")
		rootLogger.critical("Set this parameter or remove Oracle monitoring from config file")
		rootLogger.critical("Shutting down")
		exit(1)
	try:
		oracle_home = os.environ['ORACLE_HOME']
	except:
		rootLogger.critical("Environment variabele ORACLE_HOME not set. MIOS-AGENT will not function without it.")
		rootLogger.critical("Set this parameter or remove Oracle monitoring from config file")
		rootLogger.critical("Shutting down")
		exit(1)
	try:
		oracle_lib = os.environ['LD_LIBRARY_PATH']
	except:
		rootLogger.critical("Environment variabele LD_LIBRARY_PATH not set. MIOS-AGENT will not function without it.")
		rootLogger.critical("Set this parameter or remove Oracle monitoring from config file")
		rootLogger.critical("Shutting down")
		exit(1)

class MagentDaemon(Daemon):

	def run(self):

		global vp
		global config
		global probes
		global oracle
		global postgres
		global net_stat
		global rootLogger
		global mongodb
	
		config_file = ''

		config_file = magent_home + '/conf/mios-agent.conf'

		config  = Config(config_file)
		config.parse()

		try:
			logging.config.fileConfig(magent_home + '/conf/logging.conf')
		except:
			print "Error while loading file necessary for the log facility ($MAGENT_HOME/conf/logging.conf)"
			print "Unable to continue"
			exit(1)

		rootLogger = logging.getLogger()

		rootLogger.info('============================= Initialize MIOS-AGENT =================================')
		checkMAgentEnvironment()

		if not config.oracle_sids:
			rootLogger.info('No Oracle database present in config file. Skipping creation of connectionpool.')
		else:
			checkOracleEnvironment()
			oracle = Oracle(config.oracle_sids)

		if not config.postgres_dbs:
			rootLogger.info('No Postgres database present in config file. Skipping creation of connectionpool')
		else:
			postgres = Postgres(config.postgres_dbs)

		if not config.mongo_db:
			rootLogger.info('No MongoDB present in config file. Skipping creation of connectionpool')
		else:
			mongodb = MongoDB()

		probes = Probes()
		net_stat = NetStats()

		# Creating threads
		connectionThread = createThread(socketListener)
#		loggingThread = createThread(monitorLogging, 60)
#		probesCacheThread = createThread(refreshProbesCache, 600)
#		reparseConfigThread = createThread(reparseConfig, 60)
		#Starting threads
		rootLogger.info('============================= Start MIOS-AGENT ======================================')
		connectionThread.start()
#		loggingThread.start()
#		probesCacheThread.start()
#		reparseConfigThread.start()
		connectionThread.join()

if __name__ == "__main__":

	daemon = MagentDaemon('/var/run/mios/mios-agent.pid', '/tmp/mios-agent.stdout', '/tmp/mios-agent.stderr')
	if len(sys.argv) == 2:
		if 'start' == sys.argv[1]:
			daemon.start()
		elif 'stop' == sys.argv[1]:
			daemon.stop()
		elif 'restart' == sys.argv[1]:
			daemon.restart()
		else:
			print "Unknown command: %s" % sys.argv[1]
			sys.exit(2)
		sys.exit(0)
	else:
		print "usage: %s start|stop|restart" % sys.argv[0]
		sys.exit(2)
